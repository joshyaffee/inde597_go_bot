{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class env:\n",
    "    \"\"\"\n",
    "    This class is used to define a tic tac toe environment\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.previous_board = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        self.board = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        self.turn = 1\n",
    "        self.winner = 0\n",
    "\n",
    "    def reset(self, position = None):\n",
    "        if position is None:\n",
    "            position = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        if type(position) != list:\n",
    "            raise ValueError(\"The position must be a list of 9 elements\")\n",
    "        if len(position) != 9:\n",
    "            raise ValueError(\"The position must be a list of 9 elements\")\n",
    "        self.board = position\n",
    "        self.turn = 1\n",
    "        self.winner = 0\n",
    "        return self.board\n",
    "\n",
    "    def pop(self):\n",
    "        \"\"\"\n",
    "        This function is used to remove the last move\n",
    "        \"\"\"\n",
    "        self.board = self.previous_board\n",
    "        self.turn = -self.turn\n",
    "        self.winner = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        This function is used to make a move on the board\n",
    "        Returns:\n",
    "            - The new board\n",
    "            - The reward (0 if there is no winner)\n",
    "            - A boolean indicating if the game is finished\n",
    "        If the action is not possible, the game is forfeited with a reward of -10 * self.turn\n",
    "        \"\"\"\n",
    "        self.previous_board = self.board.copy()\n",
    "        if self.board[action] == 0:\n",
    "            self.board[action] = self.turn\n",
    "            self.turn = -self.turn\n",
    "            self.winner = self.check_winner()\n",
    "            done = self.winner != 0 or 0 not in self.board\n",
    "            return self.board, abs(self.winner), done\n",
    "        else:\n",
    "            return self.board, -10 * self.turn, True\n",
    "\n",
    "    def check_winner(self, board = None):\n",
    "        \"\"\"\n",
    "        This function is used to check if there is a winner\n",
    "        \"\"\"\n",
    "        if board is None:\n",
    "            board = self.board\n",
    "        for i in range(3):\n",
    "            if board[i] == board[i + 3] == board[i + 6] != 0:\n",
    "                return board[i]\n",
    "            if board[i * 3] == board[i * 3 + 1] == board[i * 3 + 2] != 0:\n",
    "                return board[i * 3]\n",
    "        if board[0] == board[4] == board[8] != 0:\n",
    "            return board[0]\n",
    "        if board[2] == board[4] == board[6] != 0:\n",
    "            return board[2]\n",
    "        if 0 not in board:\n",
    "            return 0\n",
    "        return 0\n",
    "    \n",
    "    def get_actions(self):\n",
    "        \"\"\"\n",
    "        This function is used to get the possible actions\n",
    "        \"\"\"\n",
    "        return [i for i in range(9) if self.board[i] == 0]\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        This function is used to print the board\n",
    "        \"\"\"\n",
    "        symbols = {0: \" \", 1: \"X\", -1: \"O\"}\n",
    "        return f\"{symbols[self.board[0]]}|{symbols[self.board[1]]}|{symbols[self.board[2]]}\\n-----\\n{symbols[self.board[3]]}|{symbols[self.board[4]]}|{symbols[self.board[5]]}\\n-----\\n{symbols[self.board[6]]}|{symbols[self.board[7]]}|{symbols[self.board[8]]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \"\"\"\n",
    "    This class is used to define a tic tac toe agent\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.init_policy()\n",
    "\n",
    "    def init_policy(self):\n",
    "        \"\"\"\n",
    "        This function is used to initialize the policy\n",
    "        \"\"\"\n",
    "        self.s_plus, self.s = enumerate_states()\n",
    "        self.terminals = {s for s in self.s_plus if s not in self.s}\n",
    "        self.values = {}\n",
    "        self.policy = {}\n",
    "\n",
    "        # initialize the values of the terminal states to 0\n",
    "        # initialize the policy to random and value to arbitrary value for the non\n",
    "        # terminal states\n",
    "        for state in self.s_plus:\n",
    "            if state in self.s:\n",
    "                self.values[state] = .1\n",
    "                self.policy[state] = 0\n",
    "            else:\n",
    "                self.values[state] = 0\n",
    "\n",
    "        print(\"Initialization done!\")\n",
    "\n",
    "    def get_value(self, state):\n",
    "        \"\"\"\n",
    "        This function is used to get the value of a state\n",
    "        \"\"\"\n",
    "        for iso in get_isomorphisms(state):\n",
    "            if tuple(iso) in self.values:\n",
    "                return self.values[tuple(iso)]\n",
    "        else:\n",
    "            raise ValueError(\"The state is not in the state space\")\n",
    "    \n",
    "    def get_policy(self, state):\n",
    "        symmetry0 = [0, 1, 2, 3, 4, 5, 6, 7, 8] # e\n",
    "        symmetry1 = [2, 5, 8, 1, 4, 7, 0, 3, 6] # r1\n",
    "        symmetry2 = [8, 7, 6, 5, 4, 3, 2, 1, 0] # r2\n",
    "        symmetry3 = [6, 3, 0, 7, 4, 1, 8, 5, 2] # r3\n",
    "        symmetry4 = [2, 1, 0, 5, 4, 3, 8, 7, 6] # s\n",
    "        symmetry5 = [6, 7, 8, 3, 4, 5, 0, 1, 2] # sr1\n",
    "        symmetry6 = [8, 5, 2, 7, 4, 1, 6, 3, 0] # sr2\n",
    "        symmetry7 = [0, 3, 6, 1, 4, 7, 2, 5, 8] # sr3\n",
    "        symmetries = [symmetry0, symmetry1, symmetry2, symmetry3, symmetry4, symmetry5, symmetry6, symmetry7] \n",
    "\n",
    "        for s, iso in enumerate(get_isomorphisms(state)):\n",
    "            if tuple(iso) in self.policy:\n",
    "                # the symmetry\n",
    "                sym = symmetries[s]\n",
    "                # inverse of the symmetry\n",
    "                sym_inv = [sym.index(i) for i in range(9)]\n",
    "                return sym_inv[self.policy[tuple(iso)]]\n",
    "        else:\n",
    "            raise ValueError(\"The state is not in the state space\")\n",
    "            \n",
    "    def set_value(self, state, value):\n",
    "        \"\"\"\n",
    "        This function is used to set the value of a state\n",
    "        \"\"\"\n",
    "        for iso in get_isomorphisms(state):\n",
    "            if tuple(iso) in self.values:\n",
    "                self.values[tuple(iso)] = value\n",
    "                return True\n",
    "        else:\n",
    "            raise ValueError(\"The state is not in the state space\")\n",
    "        \n",
    "    def set_policy(self, state, action):\n",
    "        for iso in get_isomorphisms(state):\n",
    "            if tuple(iso) in self.policy:\n",
    "                self.policy[tuple(iso)] = action\n",
    "                return True\n",
    "        else:\n",
    "            raise ValueError(\"The state is not in the state space\")\n",
    "       \n",
    "    def value_iteration(self, gamma = 1, theta = 1e-5):\n",
    "        delta = np.inf\n",
    "        while delta > theta:\n",
    "            delta = 0\n",
    "            for state in tqdm.tqdm(self.s):\n",
    "                self.env.reset(list(state))\n",
    "                old_v = self.get_value(state)\n",
    "                v = - np.inf\n",
    "                for action in self.env.get_actions():\n",
    "                    next_state, reward, done = self.env.step(action)\n",
    "                    v = max(v, reward + gamma * -1 * self.get_value(tuple(-1 * i for i in next_state)))\n",
    "                    self.env.pop()\n",
    "                self.set_value(state, v)\n",
    "                delta = max(delta, abs(old_v - v))\n",
    "        \n",
    "        # output policy according to the value function\n",
    "        for state in self.s:\n",
    "            self.env.reset(list(state))\n",
    "            v = - np.inf\n",
    "            for action in self.env.get_actions():\n",
    "                next_state, reward, done = self.env.step(action)\n",
    "                if reward + gamma * -1 * self.get_value(tuple(-1 * i for i in next_state)) > v:\n",
    "                    v = reward + gamma * -1 * self.get_value(tuple(-1 * i for i in next_state))\n",
    "                    best_action = action\n",
    "                self.env.pop()\n",
    "            self.set_policy(state, best_action)\n",
    "\n",
    "    def train(self, gamma = .9, theta = 1e-5):\n",
    "        self.value_iteration(gamma, theta)\n",
    "        print(\"Value iteration done!\")\n",
    "\n",
    "    def self_test(self):\n",
    "        \"\"\"\n",
    "        This function is used to test the agent\n",
    "        \"\"\"\n",
    "        self.env.reset()\n",
    "        print(self.env)\n",
    "        state = self.env.board\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = self.get_policy(tuple(state))\n",
    "            state, _, done = self.env.step(action)\n",
    "            state = [-1 * i for i in state]\n",
    "            print(self.env)\n",
    "            print()\n",
    "        if self.env.check_winner() == 0:\n",
    "            print(\"It's a draw!\")\n",
    "        elif self.env.check_winner() == 1:\n",
    "            print(\"X wins!\")\n",
    "        else:\n",
    "            print(\"O wins!\")\n",
    "    \n",
    "    def play_random(self, n=10000):\n",
    "        \"\"\"\n",
    "        This function is used to play random games\n",
    "        \"\"\"\n",
    "        wins = 0\n",
    "        draws = 0\n",
    "        losses = 0\n",
    "        for game in tqdm.tqdm(range(n)):\n",
    "            symbol = game % 2 * 2 - 1\n",
    "\n",
    "            self.env.reset()\n",
    "            state = self.env.board\n",
    "            done = False\n",
    "            while not done:\n",
    "                if symbol == self.env.turn:\n",
    "                    action = self.get_policy(tuple(state))\n",
    "                else:\n",
    "                    action = np.random.choice(self.env.get_actions())\n",
    "                state, _, done = self.env.step(action)\n",
    "                state = [-1 * i for i in state]\n",
    "            \n",
    "            if self.env.check_winner() == 0:\n",
    "                draws += 1\n",
    "            elif self.env.check_winner() == symbol:\n",
    "                wins += 1\n",
    "            else:\n",
    "                losses += 1\n",
    "        print(f\"Wins: {wins}, Draws: {draws}, Losses: {losses}\")\n",
    "        return wins, draws, losses\n",
    "\n",
    "def check_symmetry(board1, board2):\n",
    "    if board1 in get_isomorphisms(board2):\n",
    "        return True\n",
    "        \n",
    "def get_isomorphisms(board):\n",
    "    # Abstract algebra! Lol who would've thought I would ever use that\n",
    "    symmetry0 = [0, 1, 2, 3, 4, 5, 6, 7, 8] # e\n",
    "    symmetry1 = [2, 5, 8, 1, 4, 7, 0, 3, 6] # r1\n",
    "    symmetry2 = [8, 7, 6, 5, 4, 3, 2, 1, 0] # r2\n",
    "    symmetry3 = [6, 3, 0, 7, 4, 1, 8, 5, 2] # r3\n",
    "    symmetry4 = [2, 1, 0, 5, 4, 3, 8, 7, 6] # s\n",
    "    symmetry5 = [6, 7, 8, 3, 4, 5, 0, 1, 2] # sr1\n",
    "    symmetry6 = [8, 5, 2, 7, 4, 1, 6, 3, 0] # sr2\n",
    "    symmetry7 = [0, 3, 6, 1, 4, 7, 2, 5, 8] # sr3\n",
    "    symmetries = [symmetry0, symmetry1, symmetry2, symmetry3, symmetry4, symmetry5, symmetry6, symmetry7]\n",
    "    return [[board[i] for i in symmetry] for symmetry in symmetries]\n",
    "\n",
    "def enumerate_states():\n",
    "    \"\"\"\n",
    "    This function is used to enumerate all the possible states  and corresponding actions of the tic tac toe game\n",
    "    UPTO ISOMORPHISM\n",
    "\n",
    "    1 indicates agent's symbol when it's their turn so the number of 1s is at least the number of -1s minus 1\n",
    "    and at most the number of -1s\n",
    "    \"\"\"\n",
    "    isomorphic_boards = {}\n",
    "    non_terminal = set()\n",
    "    for i in range(3 ** 9):\n",
    "        board = []\n",
    "        for j in range(9):\n",
    "            board.append((i // (3 ** j)) % 3 - 1)\n",
    "        if board.count(1) < board.count(-1) - 1 or board.count(1) > board.count(-1):\n",
    "            continue\n",
    "        iso = False\n",
    "        if (board.count(1), board.count(-1)) not in isomorphic_boards:\n",
    "            isomorphic_boards[(board.count(1), board.count(-1))] = []\n",
    "\n",
    "        for ib in isomorphic_boards[(board.count(1), board.count(-1))]:\n",
    "            if check_symmetry(board, ib):\n",
    "                iso = True\n",
    "                break\n",
    "        if iso:\n",
    "            continue\n",
    "        \n",
    "        # check that the board is valid (i.e. if both players have 3 in a row, the board\n",
    "        # is invalid)\n",
    "        \n",
    "        winners = num_winners(board)\n",
    "        if winners > 1: \n",
    "            continue\n",
    "        if winners == 0 and board.count(0) > 0:\n",
    "            non_terminal.add(tuple(board))\n",
    "        \n",
    "        isomorphic_boards[(board.count(1), board.count(-1))].append(board)\n",
    "\n",
    "    s_plus = set()\n",
    "    for k, v in isomorphic_boards.items():\n",
    "        for board in v:\n",
    "            s_plus.add(tuple(board))\n",
    "    s = non_terminal\n",
    "    return s_plus, s\n",
    "\n",
    "def num_winners(board):\n",
    "    winners = set()\n",
    "    for i in range(3):\n",
    "        if board[i] == board[i + 3] == board[i + 6] != 0:\n",
    "            winners.add(board[i])\n",
    "        if board[i * 3] == board[i * 3 + 1] == board[i * 3 + 2] != 0:\n",
    "            winners.add(board[i * 3])\n",
    "        if board[0] == board[4] == board[8] != 0:\n",
    "            winners.add(board[0])\n",
    "        if board[2] == board[4] == board[6] != 0:\n",
    "            winners.add(board[2])\n",
    "    return len(winners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization done!\n"
     ]
    }
   ],
   "source": [
    "ttt = env()\n",
    "a = Agent(ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 627/627 [00:00<00:00, 721.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value iteration done!\n"
     ]
    }
   ],
   "source": [
    "a.train(gamma = .9, theta = 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.self_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:07<00:00, 1301.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins: 6146, Draws: 3689, Losses: 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6146, 3689, 165)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.play_random(10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
